<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!--Open Graph Related Stuff-->
    <meta property="og:title" content="VQA and Dialog Workshop 2020" />
    <meta property="og:url" content="http://visualqa.org/workshop.html" />
    <meta property="og:description" content="June 14 at CVPR 2020" />
    <meta property="og:description" content="CVPR 2020" />
    <meta property="og:site_name" content="Visual Question Answering and Dialog" />
    <meta property="og:image" content="http://visualqa.org/static/img/vqa_facebook_teaser_v4_jpg_100.jpg" />
    <meta property="og:image:url" content="http://visualqa.org/static/img/vqa_facebook_teaser_v4_jpg_100.jpg" />
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="VQA and Dialog Workshop 2020">
    <meta name="twitter:description" content="June 14 at CVPR 2020">
    <meta name="twitter:description" content="CVPR 2020">
    <meta name="twitter:image" content="http://visualqa.org/static/img/vqa_facebook_teaser_v4_jpg_100.jpg">
    <title>VQA: Visual Question Answering</title>
    <link rel="stylesheet" href="./static/css/foundation.css">
    <link rel="stylesheet" href="./static/css/main.css">
    <script src="./static/js/vendor/jquery.js"></script>
    <script src="./static/js/jquery-2.1.3.min.js"></script>

    <script type="text/javascript" src="./static/js/jquery.countdown.min.js"></script>
    <script type="text/javascript" src="./static/js/moment.min.js"></script>
    <script type="text/javascript" src="./static/js/moment-timezone-with-data.min.js"></script>

    <script type="text/javascript" src="./static/js/main-vqa.js"></script>
    <script type="text/javascript" src="./static/js/main-gqa.js"></script>
    <script type="text/javascript" src="./static/js/main-visdial.js"></script>
    <script type="text/javascript" src="./static/js/main-textvqa.js"></script>
    <script type="text/javascript" src="./static/js/main-textcaps.js"></script>
    <script type="text/javascript" src="./static/js/main-vizwiz.js"></script>

</head>
<style type="text/css">
.schedule table {
    -webkit-border-radius: 5px;
    -moz-border-radius: 5px;
    border-radius: 5px;
}

.schedule tr:hover {
    background-color: #D3D3D3;
}

.schedule img {
    max-height: 95px;
    max-width: 140px;
    margin-right: 2px;
    margin-top: 4px;
    margin-bottom: 4px;
    border-radius: 50%;
}
</style>

<body class="off-canvas hide-extras" style="min-width:1300px; min-height:750px;">
    <header>
        <div class="row">
            <a href="http://visualqa.org/"><img style="height: 100px; position:absolute; top:4px; left:0px;" src="./static/img/main.png" alt="logo" /></a>
            <h1><img style="height: 90px;" src="./static/img/logo.png" alt="logo" /><br></h1>
            <br>
        </div>
    </header>
    <div class="contain-to-grid">
        <nav class="top-bar" data-topbar>
            <section class="top-bar-section">
                <!-- Right Nav Section -->
                <ul class="right">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="people.html">People</a></li>
                    <li><a href="code.html">Code</a></li>
                    <li><a href="http://vqa.cloudcv.org/" onClick="ga('send', 'event', { eventCategory: 'Outgoing Link', eventAction: 'Demo', eventLabel: 'Demo'});">Demo</a></li>
                    <li class="has-dropdown"><a href="download.html">Download</a>
                        <ul class="dropdown">
                            <li><a href="download.html">VQA v2</a></li>
                            <li><a href="vqa_v1_download.html">VQA v1</a></li>
                        </ul>
                    </li>
                    <li><a href="evaluation.html">Evaluation</a></li>
                    <li class="has-dropdown"><a href="challenge.html">Challenge</a>
                        <ul class="dropdown">
                            <li><a href="challenge.html">2021</a></li>
                            <li><a href="challenge_2020.html">2020</a></li>
                            <li><a href="challenge_2019.html">2019</a></li>
                            <li><a href="challenge_2018.html">2018</a></li>
                            <li><a href="challenge_2017.html">2017</a></li>
                            <li><a href="challenge_2016.html">2016</a></li>
                        </ul>
                    </li>
                    <li class="has-dropdown"><a href="http://visualqa.org/vqa_v2_teaser.html">Browse</a>
                        <ul class="dropdown">
                            <li><a href="http://visualqa.org/vqa_v2_teaser.html">VQA v2</a></li>
                            <li><a href="https://vqabrowser.cloudcv.org/">VQA v1</a></li>

                        </ul>
                    </li>
                    <li><a href="http://visualqa.org/visualize/">Visualize</a></li>
                    <!--                     <li class="has-dropdown"><a href="http://visualqa.org/visualize/">Visualize</a>
                        <ul class="dropdown">
                            <li><a href="http://visualqa.org/visualize/">VQA v2</a></li>
                            <li><a href="http://visualqa.org/visualize/">VQA v1</a></li>
                        </ul>
                    </li> -->
                    <li class="active has-dropdown"><a href="workshop.html">Workshop</a>
                        <ul class="dropdown">
                            <li><a href="workshop.html">2021</a></li>
                            <li><a href="workshop_2020.html">2020</a></li>
                            <li><a href="workshop_2019.html">2019</a></li>
                            <li><a href="workshop_2018.html">2018</a></li>
                            <li><a href="workshop_2017.html">2017</a></li>
                            <li><a href="workshop_2016.html">2016</a></li>
                        </ul>
                    </li>
                    <li><a href="sponsors.html">Sponsors</a></li>
                    <li><a href="terms.html">Terms</a></li>
                    <li><a href="external.html">External</a></li>
                </ul>
            </section>
        </nav>
    </div>
    <section role="main" style="padding: 1em;">
        <div class="row">
            <p style="font-size:30px; color:black; font-weight: 50" align=center>Visual Question Answering and Dialog Workshop
                <br>
                <span style="font-size:18px; color:gray; font-weight: 50" align=center>at CVPR 2020, June 14</span>
                <br>
                <span style="font-size:20px; color:black; font-weight: 400" align=center>Corresponding page on CVPR 2020 website: <a target="_blank" href="http://cvpr20.com/visual-question-answering-and-dialog/">http://cvpr20.com/visual-question-answering-and-dialog</a></b></span>
                <br>
                <span style="font-size:20px; color:black; font-weight: 400" align=center>Please use the above website to join the live sessions and ask questions using text based chat.</b></span>
            </p>


            <table width="100%">
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span> <br>
                        Recording: <a target="_blank" href="https://youtu.be/8TQbkBB_Q9g">[Video]</a> </center>
                    </td>
                    <td style="padding-left:8px"><b>Panel-1: Future Directions</b>
                      <br>Danna Gurari, Felix Hill, Mateusz Malinowski, Jiasen Lu, Dimosthenis Karatzas, Nassim Parvin
                      <br><a target="_blank" href="#panel-1">[More Info]</a>
                    </td>
                    <td width=200>
                        <center>Starts June 14, 9 AM PT!</center>
                    </td>
                </tr>
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span></center>
                    </td>
                    <td style="padding-left:8px"><b>Live QA-1</b>
                      <br>Individual live QA for challenge related talks and poster spotlight presenters.
                      <br><a target="_blank" href="#live-qa-1">[More Info]</a>
                    </td>
                    <td width=200>
                        <center>Starts June 14, 12 PM PT!</center>
                    </td>
                </tr>
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span> <br>
                            Recording: <a target="_blank" href="https://youtu.be/W_8cbkjkI6I">[Video]</a></center>
                    </td>
                    <td style="padding-left:8px"><b>Panel-2: Future Directions</b>
                      <br>Douwe Kiela, Anna Rohrbach, Amanpreet Singh, Ani Kembhavi, Zhou Yu
                      <br><a target="_blank" href="#panel-2">[More Info]</a>
                    </td>
                    <td width=200>
                        <center>Starts June 14, 3 PM PT!</center>
                    </td>
                </tr>
                <tr>
                    <td width=150>
                        <center> <span style="color:gray;"><b>Ended</b></span></center>
                    </td>
                    <td style="padding-left:8px"><b>Live QA-2</b>
                        <br>Individual live QA for challenge related talks and poster spotlight presenters.
                        <br><a target="_blank" href="#live-qa-2">[More Info]</a>
                      </td>
                      <td width=200>
                          <center>Starts June 15, 12 AM PT!</center>
                      </td>
                </tr>
            </table>

            <br>
            <br>

            <p style="font-size:20px; color:black; font-weight: 50" align=center>
                <a href="workshop.html" style="padding:13px">Home</a>
                <a href="#program" style="padding:13px">Program</a>
                <a href="posters_2020.html" style="padding:13px">Poster Spotlights</a>
            </p>
                <!-- <br> -->
            <!-- <p style="font-size:20px; color:black; font-weight: 50" align=center><a href="workshop.html" style="padding:13px">Home</a> <a href="#program" style="padding:13px">Program</a> <a href="#sub" style="padding:13px">Submission</a>
                 <a href="abstracts.html" style="padding:13px">Accepted Abstracts</a></p> -->
            <hr>
            <div class="large-12 columns">
                <!-- <img src="./static/img/challenge.png" height="900" width="500" style="display:block; margin:auto;" frameBorder="0"> -->
                <img src="./static/img/visualqa_workshop.png" height="900" width="1200" style="display:block; margin:auto;" frameBorder="0">
            </div>
        </div>
        <br>
        <br>

        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Introduction</h1>
            <div class="large-12 columns" style="text-align:left;">
                <p style="font-size:15px; font-weight: 400; text-align:left">
                  The primary goal of this workshop is two-fold. First is to benchmark progress in Visual Question Answering and Visual Dialog.

                  <ul style="font-size:15px;">
                    <span style="font-size:20px;">Visual Question Answering</span><br>
                    There will be three tracks in the Visual Question Answering Challenge this year.<br><br>
                    <li style="margin-left:30px">
                      VQA: This track is the 5th challenge on the <a target="_blank" href="http://visualqa.org/download.html">VQA v2.0 dataset</a> introduced in <a target="_blank" href="https://arxiv.org/abs/1612.00837">Goyal et al., CVPR 2017</a>.
                      The <a target="_blank" href="http://visualqa.org/challenge_2017.html">2nd</a>, <a target="_blank" href="http://visualqa.org/challenge_2018.html">3rd</a> and <a target="_blank" href="http://visualqa.org/challenge.html">4th</a> editions were organised at CVPR 2017, CVPR 2018 and CVPR 2019 on the VQA v2.0 dataset, and the <a target="_blank" href="http://visualqa.org/challenge_2016.html">1st edition</a> was organised at CVPR 2016 on the <a target="_blank" href="http://visualqa.org/vqa_v1_download.html">VQA v1.0 dataset</a> introduced in <a target="_blank" href="http://arxiv.org/abs/1505.00468">Antol et al., ICCV 2015</a>.
                      VQA v2.0 is more balanced and reduces language biases over VQA v1.0, and is about twice the size of VQA v1.0.
                      <br>
                      <p style="font-size:5px"></p>
                              Challenge link: <a target="_blank" href="https://visualqa.org/challenge">https://visualqa.org/challenge</a><br>
                              Evaluation Server: <a target="_blank" href="https://evalai.cloudcv.org/web/challenges/challenge-page/514/overview">https://evalai.cloudcv.org/web/challenges/challenge-page/514/overview</a><br>
                              Submission Deadline: Friday, May 15, 2020 23:59:59 GMT (<span id="countdown-vqa"></span>)
                    </li>
                    <br>

                    <li style="margin-left:30px">
                        TextVQA+TextCaps: There are 2 subtracks under this track.
                        <br>
                        <br>
                        <li style="margin-left:60px">
                            TextVQA: This sub-track is the 2nd challenge on the TextVQA dataset introduced in <a target="_blank" href="https://textvqa.org/paper">Singh et al., CVPR 2019</a>.
                            TextVQA requires models to read and reason about text in an image to answer questions based on them.
                            In order to perform well on this task, models need to first detect and read text in the images.
                            Models then need to reason about this to answer the question.
                            The <a target="_blank" href="https://textvqa.org/challenge/2019">1st edition</a> of the TextVQA Challenge was organised at CVPR 2019.
                            <br>
                            <!-- <p style="font-size:5px"></p> -->
                                    Challenge link:  <a target="_blank" href="https://textvqa.org/challenge">https://textvqa.org/challenge</a><br>
                                    Evaluation Server: <a target="_blank" href="https://evalai.cloudcv.org/web/challenges/challenge-page/551/overview/">https://evalai.cloudcv.org/web/challenges/challenge-page/551/overview</a><br>
                                    Submission Deadline: May 15, 2020 23:59:59 GMT (<span id="countdown-textvqa"></span>)
                                    <!-- <b>[Extended]</b> -->
                        </li>
                        <br>
                        <li style="margin-left:60px">
                            TextCaps: TextCaps requires models to read and reason about text in images to generate captions about them.
                            Specifically, models need to incorporate a new modality of text present in the images and reason over it and visual content in the image to generate image descriptions.
                            <br>
                            <!-- <p style="font-size:5px"></p> -->
                                    Challenge link:  <a target="_blank" href="https://textvqa.org/textcaps/challenge">https://textvqa.org/textcaps/challenge</a><br>
                                    Evaluation Server: <a target="_blank" href="https://evalai.cloudcv.org/web/challenges/challenge-page/573/overview/">https://evalai.cloudcv.org/web/challenges/challenge-page/573/overview</a><br>
                                    Submission Deadline: May 15, 2020 23:59:59 GMT (<span id="countdown-textcaps"></span>)
                                    <!-- <b>[Extended]</b> -->
                          </li>

                    </li>
                    <br>

                    <li style="margin-left:30px">
                        VizWiz: This track is the 2nd VQA challenge on the <a target="_blank" href="https://vizwiz.org/tasks-and-datasets/vqa/">VizWiz dataset</a> introduced in <a target="_blank" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Gurari_VizWiz_Grand_Challenge_CVPR_2018_paper.pdf">Gurari et al., CVPR 2018</a>.
                        The <a target="_blank" href="https://vizwiz.org/workshops/2018-workshop/">1st edition</a> was organized at ECCV2018 on a deprecated version. 
                        This track focuses on answering visual questions that originate from a real use case where blind people were submitting images with recorded spoken questions in order to learn about their physical surroundings.
                        <br>
                        <p style="font-size:5px"></p>
                                Challenge link: <a target="_blank" href="https://vizwiz.org/tasks-and-datasets/vqa/">https://vizwiz.org/tasks-and-datasets/vqa/</a><br>
                                Evaluation Server: <a target="_blank" href="https://evalai.cloudcv.org/web/challenges/challenge-page/523/overview">https://evalai.cloudcv.org/web/challenges/challenge-page/523/overview</a><br>
                                Submission Deadline: Friday, May 15, 2020 23:59:59 PM GMT (<span id="countdown-vizwiz"></span>)
                      </li>
                      <br>

                    <span style="font-size:20px">Visual Dialog</span><br>
                    <li style="margin-left:30px">
                      The 3rd edition of the Visual Dialog Challenge will be hosted on the VisDial v1.0 dataset introduced in  <a target="_blank" href="https://arxiv.org/abs/1611.08669">Das et al., CVPR 2017</a>.
                      The <a target="_blank" href="https://visualdialog.org/challenge/2018">1st</a> and <a target="_blank" href="https://visualdialog.org/challenge/2019">2nd</a> editions of the Visual Dialog Challenge was organised on the <a target="_blank" href=-"https://visualdialog.org/data">VisDial v1.0 dataset</a> at ECCV 2018 and CVPR 2019.
                      Visual Dialog requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content.
                      Specifically, given an image, a dialog history (consisting of the image caption and a sequence of previous questions and answers), the agent has to answer a follow-up question in the dialog.
                      <br>
                      <p style="font-size:5px"></p>
                               Challenge link: <a target="_blank" href="https://visualdialog.org/challenge">https://visualdialog.org/challenge</a><br>
                               Evaluation Server: <a target="_blank" href="https://evalai.cloudcv.org/web/challenges/challenge-page/518/overview">https://evalai.cloudcv.org/web/challenges/challenge-page/518/overview</a><br>
                               Submission Deadline: May 14, 2020 23:59:59 GMT (<span id="countdown-visdial"></span>)
                    </li>

                    <br>
                    The second goal of this workshop is to continue to bring together researchers interested in visually-grounded question answering, dialog systems, and language in general to share state-of-the-art approaches, best practices, and future directions in multi-modal AI.
                    In addition to invited talks from established researchers, we invite submissions of extended abstracts of at most 2 pages describing work in the relevant areas including: Visual Question Answering, Visual Dialog, (Textual) Question Answering, (Textual) Dialog Systems, Commonsense knowledge, Vision + Language, etc.
                    The submissions are not specific to any challenge track.
                    All accepted abstracts will be presented as posters at the workshop to disseminate ideas.
                    The workshop is on June 14, 2020, at the <a target="_blank" href="http://cvpr2020.thecvf.com/">IEEE Conference on Computer Vision and Pattern Recognition, 2020</a>.
                    <br><br>

                </p>
            </div>
            <hr>
        </div>
        <div class="row">
            <a name="zhou"></a>
            <h1 style="font-size:30px; color:grey; font-weight: 200">Invited Speakers and Panelists</h1>
            <div class="team" id="people">
                <div class="row">
                    <!-- <div class="large-1 columns">
                        <p></p>
                    </div> -->
                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.ischool.utexas.edu/~dannag/AboutMe.html"><img src="./static/invited/speakers_2020/danna.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Danna Gurari</a>
                        <br>University of Texas at Austin</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://fh295.github.io/"><img src="./static/invited/speakers_2020/felix.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Felix Hill</a>
                        <br>DeepMind</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://douwekiela.github.io/"><img src="./static/invited/speakers_2020/douwe.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Douwe Kiela</a>
                        <br>Facebook AI Research</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://anna-rohrbach.net/"><img src="./static/invited/speakers_2020/anna.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Anna Rohrbach
                        </a>
                        <br>UC Berkeley</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="http://mateuszmalinowski.herokuapp.com/"><img src="./static/invited/speakers_2020/mateusz.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Mateusz Malinowski
                        </a>
                        <br>DeepMind</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://apsdehal.in/"><img src="./static/invited/speakers_2020/aman.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Amanpreet Singh
                        </a>
                        <br>Facebook AI Research</p>
                    </div>

                    <!-- <div class="large-1 columns"><p></p></div> -->
                </div>
                <div class="row">
                    <!-- <div class="large-1 columns" style="padding-left:0px">
                        <p></p>
                    </div> -->
                    <div class="large-1 columns">
                        <p></p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="http://nassim.lmc.gatech.edu/"><img src="./static/invited/speakers_2020/nassim.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Nassim Parvin
                        </a>
                        <br>Georgia Tech</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://anikem.github.io/""><img src="./static/invited/speakers_2020/ani.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Ani Kembhavi
                        </a>
                        <br>Allen Institute for Artificial Intelligence</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cc.gatech.edu/~jlu347/"><img src="./static/invited/speakers_2020/jiasen.png" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Jiasen Lu
                        </a>
                        <br>Allen Institute for Artificial Intelligence</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="http://www.cvc.uab.es/~dimos/"><img src="./static/invited/speakers_2020/dimosthenis.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Dimosthenis Karatzas
                        </a>
                        <br>Universitat Autónoma de Barcelona</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="http://zhouyu.cs.ucdavis.edu/"><img src="./static/invited/speakers_2020/zhou.jpg" class="home_team_picture" style="width:150px; height:150px;">
                            <br>
                            <p style="font-weight: 200;">Zhou Yu
                        </a>
                        <br>University of California, Davis</p>
                    </div>
                    <div class="large-2 columns"></div>


                </div>
                <!-- <br> -->
                <!-- <span style="margin-left:500px">More speakers to be added.</span> -->
                <hr>
            </div>
        </div>

        <div class="row" id="program">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Program</h1>
            Corresponding page on CVPR 2020 website: <a target="_blank" href="http://cvpr20.com/visual-question-answering-and-dialog/">http://cvpr20.com/visual-question-answering-and-dialog</a>.
            <br>
            Please use the above website to join the live sessions and ask questions using text-based chat.
            <br>
            <br>
            <br>

            <h2 style="font-size:25px; color:red; font-weight: 200"><b>Live</b></h2>
            <div id="content">
                <div class="schedule">
                    <table width="100%">
                        <tr id="panel-1">
                            <td width=150>
                                <center>June 14, 2020 <br> 9 AM - 9:45 AM PT</center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/speakers_2020/danna.png">
                                    <img src="./static/invited/speakers_2020/felix.jpg">
                                    <img src="./static/invited/speakers_2020/mateusz.jpg">
                                    <br>
                                    <img src="./static/invited/speakers_2020/jiasen.png">
                                    <img src="./static/invited/speakers_2020/dimosthenis.jpg">
                                    <img src="./static/invited/speakers_2020/nassim.jpg">
                            </td>
                            <td style="padding-left:8px">
                                <b>Panel-1: Future Directions</b>
                                <br>
                                Danna Gurari, Felix Hill, Mateusz Malinowski, <br> Jiasen Lu, Dimosthenis Karatzas, Nassim Parvin
                                <br>
                                <br>
                                Recording available now: <a target="_blank" href="https://youtu.be/8TQbkBB_Q9g">[Video]</a>
                                <br>
                                <br>
                                <span style="color: grey">(Panel ended) <br> To join Panel-1, visit: <a target="_blank" href="http://cvpr20.com/event/panel-1-future-directions-w64/">http://cvpr20.com/event/panel-1-future-directions-w64</a>.
                                <br>
                                <br>
                                <!-- If you can't, send us questions at <a target="_blank" href="https://forms.gle/bb6owMhwJJ9rcrSp7">https://forms.gle/bb6owMhwJJ9rcrSp7</a>. -->
                            </td>
                        </tr>
                        <tr id="live-qa-1">
                            <td width=150>
                                <center>June 14, 2020 <br>12 PM - 1:00 PM PT</center>
                            </td>
                            <td width=240>
                                <center>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <br>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Live QA-1</b>
                                <br>
                                Individual live QA for challenge related talks and poster spotlight presenters.
                                <br>
                                Join using the Zoom link for the corresponding talk on <a target="_blank" href="http://cvpr20.com/visual-question-answering-and-dialog/">http://cvpr20.com/visual-question-answering-and-dialog</a>.
                            </td>
                        </tr>
                        <tr id="panel-2">
                            <td width=150>
                                <center>June 14, 2020 <br>3 PM - 3:45 PM PT</center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/speakers_2020/douwe.jpg">
                                    <img src="./static/invited/speakers_2020/anna.png">
                                    <img src="./static/invited/speakers_2020/aman.jpg">
                                    <br>
                                    <img src="./static/invited/speakers_2020/ani.jpg">
                                    <img src="./static/invited/speakers_2020/zhou.jpg">
                            </td>
                            <td style="padding-left:8px">
                                <b>Panel-2: Future Directions</b>
                                <br>
                                Douwe Kiela, Anna Rohrbach, Amanpreet Singh, <br> Ani Kembhavi, Zhou Yu
                                <br>
                                <br>
                                Recording available now: <a target="_blank" href="https://youtu.be/W_8cbkjkI6I">[Video]</a>
                                <br>
                                <br>
                                <span style="color: grey">(Panel ended) <br> To join Panel-2, visit: <a target="_blank" href="http://cvpr20.com/event/panel-2-future-directions-w64/">http://cvpr20.com/event/panel-2-future-directions-w64</a>.
                                <br>
                                <br>
                                <!-- If you can't, send us questions at <a target="_blank" href="https://forms.gle/bb6owMhwJJ9rcrSp7">https://forms.gle/bb6owMhwJJ9rcrSp7</a>. -->
                            </td>
                        </tr>
                        <tr id="live-qa-2">
                            <td width=150>
                                <center>June 15, 2020 <br>12 AM - 1:00 AM PT</center>
                            </td>
                            <td width=240>
                                <center>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <br>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Live QA-2</b>
                                <br>
                                Individual live QA for challenge related talks and poster spotlight presenters.
                                <br>
                                Join using the Zoom link for the corresponding talk on <a target="_blank" href="http://cvpr20.com/visual-question-answering-and-dialog/">http://cvpr20.com/visual-question-answering-and-dialog</a>.
                            </td>
                        </tr>
                    </table>
                </div>
            </div>

            <br>
            <br>
            <br>

            <h2 style="font-size:25px; color:red; font-weight: 200"><b>Prerecorded</b></h2>
            <div id="content-2">
                <div class="schedule">
                    <table width="100%">
                        <tr>
                            <td width=150>
                                <center> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/aishwarya.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>Welcome</b>
                              <br>Aishwarya Agrawal (DeepMind)
                              <br><a target="_blank" href="https://youtu.be/tgJ90EvdO-E">[Video]</a>
                              <a target="_blank" href="https://drive.google.com/file/d/10Jm9dlFwWMURcHC1dtm2qef0ypKZvdk-/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>

                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/danna.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Visual Question Answering: Challenges and Opportunities for a Real-World Application</b>
                                <br>Danna Gurari (University of Texas at Austin)
                                <br>
                                <a target="_blank" href="https://youtu.be/B5kHdN23KMQ">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1sbnM_3JialNb90MAtEY4yYlI6-0KqXo4/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/felix.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Embodied language learning and the power of prediction</b>
                                <br>Felix Hill (DeepMind)
                                <br>
                                <a target="_blank" href="https://youtu.be/aVHnBDcm2Zs">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1rCWPJ7w3k96CE31uG--dvIaTtDN0HnUO/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/douwe.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Benchmarking Progress in AI: Adversarial NLI & Hateful Memes</b>
                                <br>Douwe Kiela (Facebook AI Research)
                                <br>
                                <a target="_blank" href="https://youtu.be/3iX33_qbNME">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1eajNw1AeMxg9hPssBvGdCsG-MI2fbdbx/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/anna.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Learning to fill-in-the-blanks in video and language</b>
                                <br>Anna Rohrbach (UC Berkeley)
                                <br>
                                <a target="_blank" href="https://youtu.be/PCknVDCuEjs">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1Z5pQiBg702oGDZwXxn0laVrxUHs1yn-f/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/mateusz.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Visual Question Answering and Related Topics</b>
                                <br>Mateusz Malinowski (DeepMind)
                                <br>
                                <a target="_blank" href="https://www.dropbox.com/s/6jh7t6kspjou9lt/Mateusz%20Malinowski%20-%20Invited%20Talk%20at%20the%20VQA-Dial%20Workshop%202020.mp4">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1Csm0qzQzcLLMNu_tAa35dEng0Rf9B6uH/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>


                        <tr id="vqa-challenge-2020-results">
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/ayush.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>VQA Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Ayush Shrivastava (Georgia Tech)
                                <br>
                                <a target="_blank" href="https://youtu.be/FFEAAN25IIY">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1yJISTi9PhQblI6aLgkMnojstx2frN5iY/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2020_winners/duy-kien.png">
                                    <img src="./static/invited/challenge_2020_winners/huaizu.png">
                                    <img src="./static/invited/challenge_2020_winners/vedanuij.png">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/licheng.png">
                                    <img src="./static/invited/challenge_2020_winners/xinlei.png">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/UMassAmherst.png" style="border-radius: 0%;">
                                    <img src="./static/invited/challenge_2020_winners/FAIR.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>VQA Challenge Winner Talk</b>
                                <br>Team: MoVie+GridFeat
                                <br>Members: Duy-Kien Nguyen, Huaizu Jiang, Vedanuj Goswami, Licheng Yu and Xinlei Chen
                                <br>
                                <a target="_blank" href="https://youtu.be/XvSWxpdbJxo">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1j9QE6xBq7Al_92ylmQEO4Ufq4f5n3Awa/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/aman.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>TextVQA Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Amanpreet Singh (Facebook AI Research)
                                <br>
                                <a target="_blank" href="https://youtu.be/O5y8i3OYdo8">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1ltTIyc6eubE7NerVPQI7sN7ECcoLhWkD/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2020_winners/Chenyu Gao.jpg">
                                    <img src="./static/invited/challenge_2020_winners/Qi Zhu.jpg">
                                    <img src="./static/invited/challenge_2020_winners/Peng Wang.jpg">
                                    <img src="./static/invited/challenge_2020_winners/Hui Li.jpg">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/Yuliang Liu.jpg">
                                    <img src="./static/invited/challenge_2020_winners/Anton Van Den Hengel.jpg">
                                    <img src="./static/invited/challenge_2020_winners/Qi Wu.jpg">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/npu.png" style="border-radius: 0%;">
                                    <img src="./static/invited/challenge_2020_winners/adel.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>TextVQA Challenge Winner Talk</b>
                                <br>Team: NWPU_Adelaide_Team
                                <br>Members: Chenyu Ga, Qi Zhu, Peng Wang, Hui Li, Yuliang Liu, Anton van den Hengel and Qi Wu
                                <br>
                                <a target="_blank" href="https://youtu.be/61abzUHhmfw">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1tJ9yK6U6fNkMAV-vLzWPzihaKB80KnsH/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/speakers_2020/danna.png">
                                    <img src="./static/invited/speakers_2020/samreen.png">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>VizWiz-VQA Challenge Talk (Overview and Winner Announcement)</b>
                                <br>Danna Gurari, Samreen Anjum
                                <br>(University of Texas at Austin)
                                <br>
                                <a target="_blank" href="https://youtu.be/yuY2F05LJ_Y">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1e5Vy4T2TakXGYgEIymf9gfx6w1cdbZ6y/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr id="vizwizwinner">
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2020_winners/Runze_Zhang.png">
                                    <img src="./static/invited/challenge_2020_winners/Xiaochuan_Li.png">
                                    <img src="./static/invited/challenge_2020_winners/Liang_Jin.png">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/Baoyu_Fan.png">
                                    <img src="./static/invited/challenge_2020_winners/Zhenhua_Guo.png">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/Logo_Inspur.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Vizwiz-VQA Challenge Winner Talk</b>
                                <!-- <br>Team:  -->
                                <br>Members: Runze Zhang, Xiaohchuan Li, Liang Jin, Baoyu Fan and Zhenhua Guo
                                <br>
                                <a target="_blank" href="https://youtu.be/wLQjneFlPrE">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1IyMa0UcF4roPbGBe-iFkPWFjlQ8A79Gx/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr id="vizwizwinner">
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2020_winners/Zhicheng Guo.jpeg">
                                    <img src="./static/invited/challenge_2020_winners/Jiaxuan Zhao.jpeg">
                                    <img src="./static/invited/challenge_2020_winners/Yan Zhang.jpeg">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/IPIU logo.jpeg" style="border-radius: 0%;">
                                    <img src="./static/invited/challenge_2020_winners/Xidian University logo.png" style="border-radius: 0%;">
                                    <br>
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>VizWiz-VQA Challenge Runner-up Talk</b>
                                <br>Team: Sudoku
                                <br>Members: Zhicheng Guo, Jiaxuan Zhao, Yan Zhang and Licheng Jiao
                                <br>
                                <a target="_blank" href="https://youtu.be/GqfzEKHO2Yc">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1zLCcBDCKOrFjzy_Bzj8FR0XUfUsY-iw_/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                    <img src="./static/invited/poster.png" style="width: 80px; height: 80px; border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Poster Spotlights</b>
                                <br>
                                To watch the poster spotlights, visit: <a href="posters_2020.html">https://visualqa.org/posters_2020</a>.
                                <!-- <br>Location: Pacific Arena Ballroom
                                <br> Allotted Poster Boards: #168 to #207 -->
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/oleksii.png"></center>
                            </td>
                            <td style="padding-left:8px"><b>TextCaps Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Oleksii Sidrov (Facebook AI Research)
                                <br>
                                <a target="_blank" href="https://youtu.be/9utGevwrSj8">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1Rzls-AC3Eu_UneBHpd63sa-wDVaOp_sh/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2020_winners/Zhaokai.png">
                                    <img src="./static/invited/challenge_2020_winners/Renda.png">
                                    <img src="./static/invited/challenge_2020_winners/Si.png">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/beihang.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>TextCaps Challenge Winner Talk</b>
                                <br>Team: colab_buaa
                                <br>Members: Zhaokai Wang, Renda Bao and Si Liu
                                <br>
                                <a target="_blank" href="https://youtu.be/8dmbbvxi-OA">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1Itl5IWoVtNyhq-SMDgn6FWbmhNdP4PpT/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/vishvak.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>Visual Dialog Challenge Talk (Overview, Analysis and Winner Announcement)</b>
                                <br>Vishvak Murahari (Georgia Tech)
                                <br>
                                <a target="_blank" href="https://youtu.be/cE3qUyOG3RQ">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1p1pjAIABUb9znaHS5nLeWWec3NzK6XWm/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#live-qa-1">Live QA-1</a> or <a href="#live-qa-2">Live QA-2</a></center>
                            </td>
                            <td width=500>
                                <center>
                                    <img src="./static/invited/challenge_2020_winners/idan.png">
                                    <img src="./static/invited/challenge_2020_winners/alex.png">
                                    <img src="./static/invited/challenge_2020_winners/tamir.png">
                                    <br>
                                    <img src="./static/invited/challenge_2020_winners/technion.png" style="border-radius: 0%;">
                                    <img src="./static/invited/challenge_2020_winners/illinois.png" style="border-radius: 0%;">
                                </center>
                            </td>
                            <td style="padding-left:8px"><b>Visual Dialog Challenge Winner Talk</b>
                                <br>Team: Technion
                                <br>Members: Idan Schwartz, Alex Schwing and Tamir Hazan
                                <br>
                                <a target="_blank" href="https://www.dropbox.com/s/nfxv2ai8fqhcb9o/Technion%20-%20Visual%20Dialog%20Challenge%20Winner%20Talk%20at%20the%20VQA-Dial%20Workshop%202020.mp4">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/17y9MRkYpYIoaKFueUrbP4PQyajcQeRp4/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>

                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/aman.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Supercharging Vision and Language Research with MMF</b>
                                <br>Amanpreet Singh (Facebook AI Research)
                                <br>
                                <a target="_blank" href="https://youtu.be/_dk4CM0vQ3M">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1kaPv_26kZfhILJiwQfeds9soK5FyfejI/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/ani.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Grounding Situations</b>
                                <br>Ani Kembhavi (Allen Institute for Artificial Intelligence)
                                <br>
                                <a target="_blank" href="https://youtu.be/li3lEhSDpe8">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1co0rlm4lf2Ue4LEJfdvJBqtJJAC3J9OQ/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/jiasen.png"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Multi-Task Vision and Language Representation Learning</b>
                                <br>Jiasen Lu (Allen Institute for Artificial Intelligence)
                                <br>
                                <a target="_blank" href="https://youtu.be/PLehRKwYWyE">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1zRACNoOTeP7wxnAmXDWqOvESn9RBJ7il/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-1">Panel-1</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/dimosthenis.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Scene Text VQA: Modelling the interplay between visual and textual information</b>
                                <br>Dimosthenis Karatzas (Universitat Autónoma de Barcelona)
                                <br>
                                <a target="_blank" href="https://youtu.be/_gGrQJsHYEg">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1JN3Jyh00-3kP_46-MsWnCLgrwTF4EvWW/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center>To ask questions, join <a href="#panel-2">Panel-2</a></center>
                            </td>
                            <td width=500>
                                <center><img src="./static/invited/speakers_2020/zhou.jpg"></center>
                            </td>
                            <td style="padding-left:8px">
                                <b>Invited Talk</b>
                                <br>
                                <b>Title: Augment Machine Intelligence with Multimodal Information</b>
                                <br>Zhou Yu (University of California, Davis)
                                <br>
                                <a target="_blank" href="https://youtu.be/1Ta4vwfpL4M">[Video]</a>
                                <a target="_blank" href="https://drive.google.com/file/d/1rooZXK7mMCnSRw5xWVLEpsU4oJTKZa0g/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                        <tr>
                            <td width=150>
                                <center> </center>
                            </td>
                            <td width=500>
                                <center><img src="./static/img/aishwarya.jpg"></center>
                            </td>
                            <td style="padding-left:8px"><b>Closing Remarks</b>
                              <br>Aishwarya Agrawal (DeepMind)
                              <br>
                              <a target="_blank" href="https://youtu.be/tMQ_fe7nmSI">[Video]</a>
                              <a target="_blank" href="https://drive.google.com/file/d/1uvPrvp9ONJe5ypEgnICPYziK6dAR2cuM/view?usp=sharing">[Slides]</a>
                            </td>
                        </tr>
                    </table>
                </div>
                <hr>
            </div>
        </div>


        <div class="row" id="sub">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Submission Instructions</h1>
            <div class="large-12 columns" style="text-align:left;">
                <p style="font-size:15px; font-weight: 400; text-align:left">We invite submissions of extended abstracts of at most 2 pages (excluding references) describing work in areas such as: Visual Question Answering, Visual Dialog, (Textual) Question Answering, (Textual) Dialog Systems, Commonsense knowledge, Video Question Answering, Video Dialog, Vision + Language, and Vision + Language + Action (Embodied Agents). Accepted submissions will be presented as posters at the workshop. The extended abstract should follow the CVPR formatting guidelines and be emailed as a single PDF to the <a href="#submit">email id</a> mentioned below.
                    <!-- Please use the following LaTeX/Word templates. -->
                    <!-- <li style="font-size:15px; font-weight: 200; text-align:left">LaTeX/Word Templates (tar): <a href="http://cvpr2019.thecvf.com/files/cvpr2019AuthorKit.tgz">cvpr2019AuthorKit.tgz</a></li> -->
                    <!-- <li style="font-size:15px; font-weight: 200; text-align:left">LaTeX/Word Templates (zip): <a href="http://cvpr2019.thecvf.com/files/cvpr2019AuthorKit.zip">cvpr2019AuthorKit.zip</a></li> -->
                </p>
                <br>

                <ul style="font-size:15px;">
                    <span style="font-size:20px;">Dual Submissions</span><br>
                    We encourage submissions of relevant work that has been previously published, or is to be presented at the main conference. The accepted abstracts will not appear in the official IEEE proceedings.
                    <br><br>

                    <span style="font-size:20px;" id="submit">Where to Submit?</span><br>
                    Please send your abstracts to <a href="mailto:visualqa.workshop@gmail.com">visualqa.workshop@gmail.com</a>
                    <br><br>
            </div>
            <hr>
        </div>
        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Dates</h1>
            <div class="large-12 columns" style="text-align:left;">
                <div class="large-12 columns" style="text-align:left;">
                    <p style="font-size:15px; font-weight: 200; border-style: solid;
                                  border-width: 1px; text-align:justify; padding:5px; width:65%">
                        <code>
                                <!-- <span style="width:40%; margin:5px; display:inline-block;">May 21, 2018</span> -->
                                <!-- <span style="width:40%; margin:5px; display:inline-block;">May 25, 2018 <span style="background-color:red; color:white;">Extended</span></span> -->
                                <span style="width:40%; margin:5px; display:inline-block;">January 2020</span>
                                <span style="display:inline-block; margin-left:100px;">Challenge Announcements</span><br>

                                <span style="width:40%; margin:5px; display:inline-block;">
                                    May 15, 2020
                                    <span style="background-color:red; color:white;">Extended</span>
                                </span>
                                <span style="display:inline-block; margin-left:100px;">Workshop Paper Submission</span><br>

                                <span style="width:40%; margin:5px; display:inline-block;">mid-May 2020</span>
                                <span style="display:inline-block; margin-left:100px;">Challenge Submission Deadlines</span><br>

                                <span style="width:40%; margin:5px; display:inline-block;">May 22, 2020</span>
                                <span style="display:inline-block; margin-left:100px;">Notification to Authors</span><br>

                                <!-- <span style="display:inline-block; margin-left:100px;">Decision to Authors</span> -->
                                <!-- <span style="width:40%; margin:5px; display:inline-block;">Apr 10, 2019</span>
                                <span style="display:inline-block; margin-left:100px;">Camera Ready Submission</span><br> -->

                                <span style="width:40%; margin:5px; display:inline-block;">June 14, 2020</span>
                                <span style="display:inline-block; margin-left:100px;">Workshop</span>
                            </code></p>
                    <!-- <p style="font-size:15px; font-weight: 400;">If you missed the deadline and are interested in presenting at the workshop, please shoot us an email.</p> -->
                </div>
            </div>
            <hr>
        </div>
        <!-- <div class="row" id="submit">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Where to Submit?</h1>
            <div class="large-12 columns" style="text-align:left;">
                <p style="font-size:15px; font-weight: 400; text-align:left">Please send your abstracts to <a href="mailto:visualqa.workshop@gmail.com">visualqa.workshop@gmail.com</a></p>
            </div>
            <hr>
        </div> -->
        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Organizers</h1>
            <div class="team" id="people">
                <div class="row">
                    <div class="large-1 columns">
                        <p></p>
                    </div>
                    <div class="large-1 columns">
                        <p></p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://ayshrv.github.io/"><img src="./static/img/ayush.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Ayush Shrivastava
                            <br>Georgia Tech</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.linkedin.com/in/drew-a-hudson/"><img src="./static/img/drew.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Drew Hudson
                            <br>Stanford University</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://vishvakmurahari.com/"><img src="./static/img/vishvak.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Vishvak Murahari
                            <br>Georgia Tech</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://abhishekdas.com/"><img src="./static/img/abhishek.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Abhishek Das
                            <br>Georgia Tech</p>
                    </div>
                    <div class="large-1 columns">
                        <p></p>
                    </div>
                    <div class="large-1 columns">
                        <p></p>
                    </div>
                </div>

                <div class="row" style="padding-left: 1em; padding-right: 1em;">
                    <div class="large-1 columns" style="padding-left:75px">
                      <p></p>
                    </div>
                    <div class="large-1 columns">
                        <p></p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://satwikkottur.github.io/"><img src="./static/img/satwik.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Satwik Kottur
                            <br>Facebook AI</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cc.gatech.edu/~dbatra/"><img src="./static/img/dhruv.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Dhruv Batra
                            <br>Georgia Tech / Facebook AI Research</p>
                    </div>
                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cc.gatech.edu/~parikh/"><img src="./static/img/devi.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200;">Devi Parikh
                            <br>Georgia Tech / Facebook AI Research</p>
                    </div>

                    <div class="large-2 columns">
                        <a target="_blank" href="https://www.cc.gatech.edu/~aagrawal307/"><img src="./static/img/aishwarya.jpg" class="home_team_picture" style="width: 125px; height:125px;">
                            <br>
                        </a>
                        <p style="font-weight: 200; margin-left:-20px;">Aishwarya Agrawal
                            <br>DeepMind</p>
                    </div>

                    <hr>
                </div>
            </div>
        </div>

        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Sponsors</h1>
            <p style="font-size:15px; font-weight: 400; text-align:left">
            This work is supported by grants awarded to Dhruv Batra and Devi Parikh.
            </p>
            <!-- <div class="large-12 columns">
                <a target="_blank" href="https://cloud.google.com/">
                    <img src="./static/img/gcp_logo.svg" style="width:250px; height:100px; margin-top:0px;">
                </a>
                <br>
            </div> -->
        </div>

        <hr>
        <div class="large-12 columns" style="background: white;">
            <p style="color:black; text-align:center; display:block; margin-top:7px;">Contact: <a href="mailto:visualqa.workshop@gmail.com" target="_top">visualqa.workshop@gmail.com</a></p>
        </div>
    </section>
    <script>
    $(document).foundation();
    </script>
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-63638588-1', 'auto');
    ga('send', 'pageview');
    </script>
    <!-- jquery smooth scroll to id's -->
    <script>
    $(function() {
        $('a[href*=#]:not([href=#])').click(function() {
            if (location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') && location.hostname == this.hostname) {
                var target = $(this.hash);
                target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
                if (target.length) {
                    $('html,body').animate({
                        scrollTop: target.offset().top
                    }, 1000);
                    return false;
                }
            }
        });
    });
    </script>
</body>

</html>
