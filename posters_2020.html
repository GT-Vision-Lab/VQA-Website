<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>VQA: Visual Question Answering</title>
    <link rel="stylesheet" href="./static/css/foundation.css">
    <link rel="stylesheet" href="./static/css/main.css">
</head>

<body class="off-canvas hide-extras" style="min-width:1200px; min-height:750px;">
    <header>
        <div class="row">
            <a href="http://visualqa.org/"><img style="height: 100px; position:absolute; top:4px; left:0px;" src="./static/img/main.png" alt="logo" /></a>
            <h1><img style="height: 90px;" src="./static/img/logo.png" alt="logo" /><br></h1>
            <br>
        </div>
    </header>
    <div class="contain-to-grid">
        <nav class="top-bar" data-topbar>
            <section class="top-bar-section">
                <!-- Right Nav Section -->
                <ul class="right">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="people.html">People</a></li>
                    <li><a href="code.html">Code</a></li>
                    <li><a href="http://vqa.cloudcv.org/" onClick="ga('send', 'event', { eventCategory: 'Outgoing Link', eventAction: 'Demo', eventLabel: 'Demo'});">Demo</a></li>
                    <li class="has-dropdown"><a href="download.html">Download</a>
                        <ul class="dropdown">
                            <li><a href="download.html">VQA v2</a></li>
                            <li><a href="vqa_v1_download.html">VQA v1</a></li>
                        </ul>
                    </li>
                    <li><a href="evaluation.html">Evaluation</a></li>
                    <li class="has-dropdown"><a href="challenge.html">Challenge</a>
                        <ul class="dropdown">
                             <li><a href="challenge.html">2021</a></li>
                            <li><a href="challenge_2020.html">2020</a></li>
                            <li><a href="challenge_2019.html">2019</a></li><li><a href="challenge_2018.html">2018</a></li>
                            <li><a href="challenge_2017.html">2017</a></li>
                            <li><a href="challenge_2016.html">2016</a></li>
                        </ul>
                    </li>
                    <li class="has-dropdown"><a href="http://visualqa.org/vqa_v2_teaser.html">Browse</a>
                        <ul class="dropdown">
                            <li><a href="http://visualqa.org/vqa_v2_teaser.html">VQA v2</a></li>
                            <li><a href="https://vqabrowser.cloudcv.org/">VQA v1</a></li>

                        </ul>
                    </li>
                    <li><a href="http://visualqa.org/visualize/">Visualize</a></li>
                    <!--                     <li class="has-dropdown"><a href="http://visualqa.org/visualize/">Visualize</a>
                        <ul class="dropdown">
                            <li><a href="http://visualqa.org/visualize/">VQA v2</a></li>
                            <li><a href="http://visualqa.org/visualize/">VQA v1</a></li>
                        </ul>
                    </li> -->
                    <li class="has-dropdown"><a href="workshop.html">Workshop</a>
                        <ul class="dropdown">
                            <li><a href="workshop.html">2021</a></li>
                            <li><a href="workshop_2020.html">2020</a></li>
                            <li><a href="workshop_2019.html">2019</a></li>
                            <li><a href="workshop_2018.html">2018</a></li>
                            <li><a href="workshop_2017.html">2017</a></li>
                            <li><a href="workshop_2016.html">2016</a></li>
                        </ul>
                    </li>
                    <li><a href="sponsors.html">Sponsors</a></li>
                    <li><a href="terms.html">Terms</a></li>
                    <li><a href="external.html">External</a></li>
                </ul>
            </section>
        </nav>
    </div>
    <section role="main" style="padding: 1em;">
        <div class="row">
            <p style="font-size:30px; color:black; font-weight: 50" align=center>Visual Question Answering and Dialog Workshop
                <br>
                <span style="font-size:18px; color:gray; font-weight: 50" align=center>at CVPR 2020, June 14</span>
                <br>
                <span style="font-size:20px; color:black; font-weight: 400" align=center>Corresponding page on CVPR 2020 website: <a target="_blank" href="http://cvpr20.com/visual-question-answering-and-dialog/">http://cvpr20.com/visual-question-answering-and-dialog</a></b></span>

            </p>
            <p style="font-size:20px; color:black; font-weight: 50" align=center>
                <a href="workshop.html" style="padding:13px">Home</a>
                <a href="#program" style="padding:13px">Program</a>
                <a href="posters_2020.html" style="padding:13px">Poster Spotlights</a>
            </p>
            <hr>
        </div>
        <div class="row">
            <h1 style="font-size:30px; color:grey; font-weight: 200">Poster Spotlights</h1>
            <div class="large-12 columns" style="text-align:left;">
                <p style="font-size:15px; font-weight: 200; text-align:left">
                    <b>BGN: Bilinear Graph Networks for Visual Question Answering (VQA Challenge Runner up)</b>
                    <br> Dalu Guo, Chang Xu, Dacheng Tao
                    <br>
                    <a target="_blank" href="https://youtu.be/ZdF3WXZCNO8">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1lK1giWqrXy2L-SxNfQDluL5pWbgDbe7W/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Visual-Linguistic Pre-training for Visual Question Answering (VQA Challenge Runner up)</b>
                    <br> Ming Yan, Chenliang Li, Wei Wang, Bin Bi, Zhongzhou Zhao, Songfang Huang
                    <br>
                    <a target="_blank" href="https://youtu.be/XvLi-QQh7wk">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1zYnoQqAMpBzdVEEkrdHy6w2h4lj4pEDK/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Knowledge-Based Visual Question Answering in Videos</b>
                    <br> Noa Garcia, Mayu Otani, Chenhui Chu, Yuta Nakashima
                    <br>
                    <a target="_blank" href="https://youtu.be/foACWpZ6tdc">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1B1Ce_aVA_Iuc6Ke02JjHnLR1DY50-ySj/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions</b>
                    <br> Kento Terao, Toru Tamaki, Bisser Raytchev, Kazufumi Kaneda, Shin'ichi Satoh
                    <br>
                    <a target="_blank" href="https://youtu.be/g24WtI3vS1Y">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1kDJKhBLxBTaFol4DIkrickWExVzCeds8/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Spatially Aware Multimodal Transformers for TextVQA</b>
                    <br>Yash Kant, Dhruv Batra, Peter Anderson, Alex Schwing, Devi Parikh, Jiasen Lu, Harsh Agrawal
                    <br>
                    <a target="_blank" href="https://youtu.be/uPZra6HfLd0">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/16L2cosOQERHyOpcozgwMfEm_ogBpbbke/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>TextCaps: a Dataset for Image Captioning with Reading Comprehension</b>
                    <br>Oleksii Sidorov, Ronghang Hu, Marcus Rohrbach, Amanpreet Singh
                    <br>
                    <a target="_blank" href="https://youtu.be/0T9oguyw2Lc">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1Y1ztKQSMzVU6oWAckzQVwIVHdh3a6zpk/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Visual Question Answering with Prior Class Semantics</b>
                    <br>Violetta Shevchenko, Damien Teney, Anthony Dick, Anton van den Hengel
                    <br>
                    <a target="_blank" href="https://youtu.be/Kdp1F6rYhqo">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1UBNNxJyc5md05eOoaJO6DN8dKHVFZl9S/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Incorporating Background Knowledge Through Embedding-Space Constraints for Visual Question Answering</b>
                    <br>Damien Teney, Ehsan Abbasnejad, Anton van den Hengel
                    <br>
                    <a target="_blank" href="https://youtu.be/VsXHhbN0Wto">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1oj1NFiW7p6KRC35gZAji1Z70YB6UtOTs/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>On the Value of Out-of-Distribution Testing - An Example of Goodhart’s Law</b>
                    <br>Damien Teney, Kushal Kafle, Robik Shrestha, Ehsan Abbasnejad, Christopher Kanan, Anton van den Hengel
                    <br>
                    <a target="_blank" href="https://youtu.be/MwwcFKA6qOQ">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1FvzfiCuTMIWJ0GnSGHOkuOPo0RgzDr6H/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Zero-Shot Grounding of Objects from Natural Language Queries</b>
                    <br>Arka Sadhu, Kan Chen, Ram Nevatia
                    <br>
                    <a target="_blank" href="https://youtu.be/ouL5_KwzywY">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1V_I61zzNRKWGycJcREU_Sg8_Oj5aKV1E/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Tricks for Training Visual dialogue Models</b>
                    <br>Guanlin Liang, Wenbin Li, Yang Liu, Sheng He, Ximin Zheng, You Wu, Xian Zhong
                    <br>
                    <a target="_blank" href="https://youtu.be/oR7_lh02RYQ">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1X4Ozm4gYOAfWHomYnVcmco2qvJ0q5aG1/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Exploring Weaknesses of VQA Models through Attribution Driven Insights</b>
                    <br>Shaunak Halbe
                    <br>
                    <a target="_blank" href="https://youtu.be/nvvEGeVGKzM">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1CaVSTBEYF7YXcozm-ve9zgqIXqcs8-NW/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Neuro-Symbolic Visual Reasoning: Disentangling ‘Visual’ from ‘Reasoning’ </b>
                    <br>Saeed Amizadeh, Oleksandr Polozov, Hamid Palangi, Yichen Huang, Kazuhito Koishida
                    <br>
                    <a target="_blank" href="https://youtu.be/k7ZBPic8zLs">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1yD_ZVAQV7Tx63rBdPGHPcDsx9ZDvcD37/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Automatic Reminiscence Therapy for Dementia</b>
                    <br>Mariona Carós, Xavier Giró-i-Nieto, Petia Radeva, Maite Garolera
                    <br>
                    <a target="_blank" href="https://youtu.be/bJmKsP1ExU4">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1aEZyLlRSckffkA4ffYr85KSd98PCvmN_/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Weakly Supervised Categoric Visual Question Generation</b>
                    <br>Shagun Uppal*, Anish Madan*, Sarthak Bhagat*, Yi Yu, Rajiv Ratn Shah
                    <br>
                    <a target="_blank" href="https://youtu.be/SuTzKcIRGuw">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1x20WD-u9H8s3JTSLJFXO1PCFftX91KYV/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Ensemble MRR and NDCG models for Visual Dialog</b>
                    <br>Idan Schwartz, Alex Schwing, Tamir Hazan
                    <br>
                    <a target="_blank" href="https://youtu.be/oS50Iupr5K4">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1L001hnKWpsMcL2UMOBif61KYQBnJ6LVS/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Controlling Length in Image Captioning</b>
                    <br>Ruotian Luo, Greg Shakhnarovich
                    <br>
                    <a target="_blank" href="https://youtu.be/YXclLInCmWo">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1EuVhGZrAjRcqvP4YyS67ryi3MjZAoxyC/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a> and <a href="workshop.html#live-qa-2">Live QA-2</a>

                    <br>
                    <br>
                    <b>Visual Question Generation from Radiology Images based on Variational Autoencoders</b>
                    <br>Mourad Sarrouti, Asma Ben Abacha, Dina Demner-Fushman
                    <br>
                    <a target="_blank" href="https://youtu.be/jdBOjitKpBo">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1LaxTuONp1Pzn-KWC1zLqbihvO4mK6hS7/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a>

                    <br>
                    <br>
                    <b>PathVQA: The First Step Towards an “AI Pathologist”</b>
                    <br>Xuehai He, Yichen Zhang, Luntian Moux, Eric P. Xing, Pengtao Xie
                    <br>
                    <a target="_blank" href="https://youtu.be/EjSJY1-D_Oc">[Video]</a>
                    <a target="_blank" href="https://drive.google.com/file/d/1R6ucxrdU4X08JXYIp2ocrF_7QkZ6xe8J/view?usp=sharing">[Slides]</a>
                    <br> Available for QA at <a href="workshop.html#live-qa-1">Live QA-1</a>

                </p>
            </div>
            <hr>
        </div>
    </section>
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-63638588-1', 'auto');
    ga('send', 'pageview');
    </script>
    <!-- jquery smooth scroll to id's -->
    <script>
    $(function() {
        $('a[href*=#]:not([href=#])').click(function() {
            if (location.pathname.replace(/^\//, '') == this.pathname.replace(/^\//, '') && location.hostname == this.hostname) {
                var target = $(this.hash);
                target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
                if (target.length) {
                    $('html,body').animate({
                        scrollTop: target.offset().top
                    }, 1000);
                    return false;
                }
            }
        });
    });
    </script>
</body>

</html>
